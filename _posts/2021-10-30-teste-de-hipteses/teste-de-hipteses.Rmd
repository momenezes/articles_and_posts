---
title: "Teste de Hipótese"
description: |
  Conceitos, cálculos e visualizações.
author:
  - name: Mario O. de Menezes
    url: https://momenezes.github.io/tutorials
    orcid_id: 0000-0003-0263-3541
date: 11-11-2021
preview: figures/regioesaceitacaorejeicao_previewimg.png
output:
  distill::distill_article:
    self_contained: true
    highlight: tango

---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r}
library(tidyverse)
library(plotly)
library(ggpubr)
library(ggthemes)
```


# Teste de Hipótese

<p style="font-size:8; font-color:#222222">Versão Preliminar</p>

## População e Amostra

Muitas vezes precisamos obter medidas de a uma *população* (todos os indivíduos de interesse do estudo); o modo inicial para se fazer isso seria obter os dados de toda a população. Mas nem sempre é possível realizar essa coleta de dados de toda a população, e isso por diversos motivos, dentre eles o custo e o tempo necessário.

Assim, é comum utilizarmos um subconjunto da população, chamado de *amostra*. Essa *amostra* deve possuir então características que nos possibilitem *inferir* os parâmetros da população. Há diversas maneiras de se selecionar os elementos da *amostra*: aleatoriamente, por grupos representativos, por representatividade na população, etc. Esses conceitos podem ser explorados em um bom livro de Estatística e Probabilidade.

A maneira mais utilizada de se selecionar os indivíduos da amostra é a aleatória, de forma independente, cuidando para que cada elemento tenha a mesma probabilidade de ser selecionado, isto é, identicamente distribuído. Uma outra característica da amostra é o seu tamanho, que será o conceito que exploraremos nesse estudo juntamente com uma característica da população, a saber, o desvio padrão.

Então, com a amostra em mãos, efetuamos os cálculos desejados e fazemos a *inferência*, isto é, uma afirmação sobre um *parâmetro* da população. Nossa afirmação pode estar correta (ser verdadeira) ou errada (ser falsa). É comum querermos atribuir um grau de confiança a esta afirmação; algo como "... é possível afirmar, com 95% de confiança, que ..."

Juntando estes conceitos, chegamos à definição (informal) de Teste de Hipótese:

> Um teste de hipótese em Estatística é uma afirmação sobre um parâmetro de uma população a partir dos dados de uma amostra.

## Distribuição de Probabilidade

Suponha que você esteja estudando o peso (massa corporal) de uma população de animais que vive em determinada região. Em um trabalho muito extenso anterior, todos os animais daquela população foram pesados, de modo que são conhecidos para a população o peso médio ( $\mathbf{\mu}$) e também a dispersão destes valores, isto é, o desvio padrão ($\mathbf{\sigma}$).

Ao *plotar* os valores do peso de cada animal e também através de algumas verificações matemáticas, conclui-se que a variável aleatória peso segue uma distribuição normal. *Variável aleatória* porque cada animal tem um peso diferente, que não tem dependência com o animal que foi pesado antes e nem vai influenciar o peso do próximo animal. 

No Teste de Hipótese, um conceito importante é *a distribuição de probabilidades* da variável aleatória que estamos estudando. É preciso conhecer essa distribuição de probabilidades; caso não seja possível esse conhecimento, será necessário fazer assunções sobre ela para realizar o teste.

```{r}
set.seed(1234)
media = 3.4
desvio = 0.7
tam = 8000
y <- rnorm(tam, mean = media, sd = desvio)
x <- seq(1:tam)
df <- tibble(x = x, `Peso(kg)` = y)
```

A distribuição normal é aquela com forma de *sino*; se adotarmos no nosso exemplo que a média de peso da população seja 3.4kg, com um desvio padrão 0.7kg, e a população que foi pesada seja de `r tam` animais, podemos ter uma *ideia* da distribuição real de probabilidades dos pesos como a mostrada na figura abaixo. Como nossa população é finita, a curva mostrada é uma estimativa da curva de densidade de probabilidade e o formato da curva não é perfeitamente um *sino*, mas se aproxima. O histograma da distribuição de pesos também é mostrado nessa figura.

```{r}
g <- ggplot(data = df, aes(x = `Peso(kg)`, after_stat(density))) + 
  geom_density(outline.type = "full") + 
  geom_histogram(alpha = 0.3 ) +
  labs(x = "Peso(kg)", y = "Densid.Prob.") +
  theme_light() 
ggplotly(g + ggtitle(paste("Distribuição dos pesos da população (n=",tam,")")))
```



O eixo *y* representa a *estimativa da densidade de probabilidade de ocorrência de x*, que é calculada de tal forma que a área sob a curva seja 1. Você pode ler mais sobre Estimativa de Densidade de Probabilidade [aqui](https://bookdown.org/egarpor/PM-UC3M/npreg-npdens.html).


<!-- algumas outras referencias sobre estimativa de densidade de probabilidade: 
https://vita.had.co.nz/papers/density-estimation.pdf
https://myweb.uiowa.edu/pbreheny/uk/teaching/621/notes/10-18.pdf
https://www.r-bloggers.com/2013/06/exploratory-data-analysis-kernel-density-estimation-in-r-on-ozone-pollution-data-in-new-york-and-ozonopolis/
https://cran.r-project.org/web/packages/kdensity/vignettes/tutorial.html
https://github.com/admond1994/calculate-probability-from-probability-density-plots/blob/master/cal_probability.ipynb
-->
<!--
Ao mover o mouse sobre os pontos, os valores de *x* e *y* são mostrados; você poderá verificar que quando se afasta da média *x = 3.4*, o valor de *y* vai ficando cada vez menor, isto é, a probabilidade de ocorrência deste valor de *x* vai ficando cada vez menor.
-->

## Amostras

Suponha que nosso biólogo colete uma amostra dos animais e faça a pesagem. Do ponto de vista da Teoria da Probabilidade, temos a seguinte definição:

> Se a população da qual se extraem as amostras tem distribuição normal, então a distribuição de probabilidade da média amostral também seguirá uma normal.

Podemos simular um experimento que realize um grande número de amostragens, calcule a média de cada amostra e depois observamos a distribuição destas médias amostrais. 

Começamos com a ilustração de uma amostra de $n = 30$ dos animais em estudo, conforme mostrado na figura abaixo, onde os pontos de cor azul representam a amostra, ou seja, os animais selecionados aleatoriamente da população.

```{r}
set.seed(1234)
n = 30
amostra <- slice_sample(df, n = n, replace = TRUE)
amostra$P0 <- 0
pesomedioamostra = mean(amostra$`Peso(kg)`)
g + geom_point(aes(x = `Peso(kg)`, y = P0), data = amostra, color = "blue") +
  geom_segment(aes(x = pesomedioamostra, y = 0, xend=pesomedioamostra, yend = 0.05), color = "red") +
  annotate("text", x = 1.0*pesomedioamostra, y = 0.07, label = paste("Méd.Am. ",  round(pesomedioamostra,2)), size = 3) +
  ggtitle(paste("Amostra de tamanho = ",n,"(pontos azuis)\nHistograma e Curva de Densid. originais"))
```


```{r}
set.seed(1234)

geragrafs <- function(g, amostra) {
  amostra$P0 <- 0
  pesomedioamostra = mean(amostra$`Peso(kg)`)
  novog <- g + geom_point(aes(x = `Peso(kg)`, y = P0), data = amostra, color = "blue") +
               geom_segment(aes(x = pesomedioamostra, y = 0, xend=pesomedioamostra, yend = 0.05), 
                            color = "red") +
               annotate("text", x = 1.0*pesomedioamostra, y = 0.08, 
                        label = paste("Méd.Am.: ",  round(pesomedioamostra,3)), size = 3)
}

geraamostras <- function(df, qts, N){
  amostras <- list()
  for (I in seq(1:qts)) {
    amostras[[I]] <- slice_sample(df, n = N, replace = TRUE)
  }
  amostras
}

```

Agora com 10 amostras com $n = 30$; veja como os valores das amostras (pontos em azul) ocorrem em cada uma. É importante lembrar deste conceito quando falamos de uma amostra, isto é, a variabilidade dos valores encontrados em uma amostra, incluindo a dispersão dos pontos em torno da média. 

```{r fig.height=20}
SSize <- 30
Qtde <- 10
amostrasN30 <- geraamostras(df, Qtde, SSize)
graficosN30 <- lapply(amostrasN30, FUN = function(x) geragrafs(g, x))

ggarrange(plotlist = graficosN30, nrow = 5, ncol = 2) %>%
  annotate_figure(top = text_grob(paste0("Experimento com ", Qtde, " amostras de tamanho = ", SSize,
                                         "\nHistograma e curva densid. originais"), face = "bold", size = 16))
```

Observe como as médias das amostras variam; ora são maiores ora menores do que a média da população ($\mu = 3.4$). 

Para ilustrar um pouco mais os conceitos de amostragem, vamos selecionar novamente 10 amostras, mas agora de tamanho $n = 10$.

```{r fig.height=20}
SSize <- 10
Qtde <- 10
amostrasN10 <- geraamostras(df, Qtde, SSize)
graficosN10 <- lapply(amostrasN10, FUN = function(x) geragrafs(g, x))

ggarrange(plotlist = graficosN10, nrow = 5, ncol = 2) %>%
  annotate_figure(top = text_grob(paste0("Experimento com ", Qtde, " amostras de tamanho = ", SSize,
                                         "\nHistograma e curva densid. originais"), face = "bold", size = 16))
```

Veja como nas amostras com $n=30$ temos uma maior concentração de pontos azuis na região próxima da média da população; isso ocorre porque temos um maior número de animais cujo peso está nessa região, isto é, peso próximo da média da população. Nas amostras com $n = 10$ os pontos azuis são mais dispersos, o que provoca uma maior dispersão das médias destas amostras também. 

Esse é outro conceito importante: **quanto maior o tamanho da amostra, mais próximo sua média será da média da população**.

Em ambas as situações temos animais com peso bem maior ou bem menor do que a média; eles são mais raros nas amostras, porque são mais raros também na população.




```{r}
set.seed(1234)
mediasamostrais <- function(amostra, N, SSize) {
  medias <- c()
  for (I in seq(1:N)) {
     amostra <- slice_sample(df, n = SSize, replace = TRUE)
     amostra$P0 <- 0
     pesomedioamostra = mean(amostra$`Peso(kg)`, na.rm = TRUE)
     medias[I] <- pesomedioamostra
  }
  return(medias)
}


```

```{r}
SSize <- 30
Qtde <- 1000
```

### Grande Número de Amostras

Vamos agora coletar `r Qtde` amostras de `r SSize` elementos; para cada amostra calculamos a média do peso dos animas e construímos um histograma com o respectivo gráfico de densidade de probabilidade, como mostrado na figura abaixo. Também calculamos a média das médias das amostras, que é mostrada na figura, juntamente com o intervalo de confiança (**CI**)de 95%.

```{r}
milamostras <- geraamostras(df, Qtde, SSize)
```

```{r}
mediasamostras <- sapply(milamostras, function(x) {
  mediaPeso <- mean(x$`Peso(kg)`, na.rm = TRUE)
  mediaPeso
}
)

mediasam_est <- t.test(mediasamostras)
mediasam_mean <- as.numeric(mediasam_est$estimate)
mediasam_confint <- as.numeric(mediasam_est$conf.int)

dfmedias <- tibble(x = mediasamostras)
ggplot(dfmedias, aes(x = x, after_stat(density))) + 
  geom_density() + 
  geom_histogram(alpha = 0.3) + 
  geom_segment(aes(x = mediasam_mean, y = 0, xend=mediasam_mean, yend = 0.15), 
                            color = "red", size = 0.15) +
  geom_segment(aes(x = mediasam_confint[1], y = 0, xend=mediasam_confint[1], yend = 0.15), 
                            color = "blue", size = 0.15) +
  geom_segment(aes(x = mediasam_confint[2], y = 0, xend=mediasam_confint[2], yend = 0.15), 
                            color = "blue", size = 0.15) +
 annotate("text", x = 1.003*mediasam_mean, y = 0.75, 
                        label = paste("Média das Médias Amostrais: \n",  round(mediasam_mean,3)), size = 3) +
 annotate("text", x = 0.993*mediasam_mean, y = 0.5, 
                        label = paste(" (%95 CI): [",  round(mediasam_confint[1],3), ",",
                                      round(mediasam_confint[2],3), "]"), size = 3) +
  labs(x = "Médias de Peso das Amostras (kg)", y = "Densid.Prob.") + 
  ggtitle(paste0("Experimento com ", Qtde, " amostras de tamanho n = ", SSize,
                 "\nHistograma e curva densid. médias amostrais")) +
  theme_light()

```



```{r}
SSize <- 10
Qtde <- 1000
```


Se repetimos este experimento com `r Qtde` amostras, mas agora com `r SSize` elementos, obtemos o seguinte resultado:

```{r}
milamostrasSS10 <- geraamostras(df, Qtde, SSize)
```


```{r}
mediasamostrasSS10 <- sapply(milamostrasSS10, function(x) {
  mediaPeso <- mean(x$`Peso(kg)`, na.rm = TRUE)
  mediaPeso
}
)

mediasam_est <- t.test(mediasamostrasSS10)
mediasam_mean <- as.numeric(mediasam_est$estimate)
mediasam_confint <- as.numeric(mediasam_est$conf.int)

dfmediasSS10 <- tibble(x = mediasamostrasSS10)
ggplot(dfmediasSS10, aes(x = x, after_stat(density))) + 
  geom_density() + 
  geom_histogram(alpha = 0.3) + 
  geom_segment(aes(x = mediasam_mean, y = 0, xend=mediasam_mean, yend = 0.15), 
                            color = "red", size = 0.15) +
  geom_segment(aes(x = mediasam_confint[1], y = 0, xend=mediasam_confint[1], yend = 0.15), 
                            color = "blue", size = 0.15) +
  geom_segment(aes(x = mediasam_confint[2], y = 0, xend=mediasam_confint[2], yend = 0.15), 
                            color = "blue", size = 0.15) +
 annotate("text", x = 1.003*mediasam_mean, y = 0.75, 
                        label = paste("Média das Médias Amostrais: \n",  round(mediasam_mean,3)), size = 3) +
 annotate("text", x = 0.993*mediasam_mean, y = 0.5, 
                        label = paste(" (%95 CI): [",  round(mediasam_confint[1],3), ",",
                                      round(mediasam_confint[2],3), "]"), size = 3) +
  labs(x = "Médias de Peso das Amostras (kg)", y = "Densid.Prob.") + 
  ggtitle(paste0("Experimento com ", Qtde, " amostras de tamanho n = ", SSize,
                 "\nHistograma e curva densid. médias amostrais")) +
  theme_light()

```



Como observamos nas figuras acima, a média das médias amostrais tende para a média verdadeira, $\mu$ = `r media`, quando tomamos um grande número de amostras; também observamos que **a distribuição das médias amostrais (S) se aproxima de uma distribuição normal**, com média $\mu_S$ e desvio padrão $\sigma_S$.

### Amostras pequenas

Mas quando o biólogo seleciona uma amostra apenas de $n = 30$ animais, o peso médio dos animais desta amostra pode ser distante da média verdadeira, como ilustrado na figura abaixo, onde uma amostra tem peso médio bem abaixo e outra com peso médio bem acima da média verdadeira; e aí podemos perguntar: 

> Será que aconteceu alguma coisa que levou a uma diminuição ou aumento geral do peso destes animais (de toda a população) ou é apenas nesta amostra? 


```{r}
mediasamostrasSS30 <- sapply(amostrasN30, function(x) {
  mediaPeso <- mean(x$`Peso(kg)`, na.rm = TRUE)
  mediaPeso
}
)
menormedia <- which(mediasamostrasSS30 == min(mediasamostrasSS30))
maiormedia <- which(mediasamostrasSS30 == max(mediasamostrasSS30))
ggarrange(graficosN30[[menormedia]],graficosN30[[maiormedia]]) %>%
  annotate_figure(top = text_grob(paste0("Amostras de tamanho n = 30",
                                         "\nHistograma e curva densid. originais"), face = "bold", size = 16))
```


Para responder a esta pergunta podemos realizar o *Teste de Hipótese*.

A primeira coisa a fazer é declarar as hipóteses que serão testadas:

* A hipótese nula ($\textrm{H}_0$) é a que expressa a ideia de que não houve alteração na média da população, ou seja, não temos *outra* população;
* A hipótese alternativa ($\textrm{H}_1$) é a que expressa a ideia complementar, ou seja, houve alguma alteração significativa, gerando uma *nova* população.

Matematicamente, escrevemos assim:

* $\textrm{H}_0: \mu = \mu_0$
* $\textrm{H}_1: \mu \neq \mu_0$

onde $\mu$ é o parâmetro conhecido da população (média) e $\mu_0$ (ou $\bar{x}$) é o valor de teste, obtido da amostra. Quando a hipótese alternativa ($\textrm{H}_1$) é expressa como **diferença** ($\neq$), temos um teste bilateral; quando $\textrm{H}_1$ é expressa como $>$ ou $<$ temos um teste unilateral. 

A conclusão do teste de hipótese é uma afirmação que pode estar certa ou errada; definimos um limite para a probabilidade de estarmos errados em nossa afirmação sobre $\textrm{H}_0$, chamado de nível de significância. São comuns valores de $0.05$ ou $0.01$ para este nível de significância, representado pela letra grega $\alpha$.

Retomando o conceito da distribuição das médias amostrais **S**, definimos a distribuição da variável reduzida (ou *escore* **z**) por $$z = \frac{(S - \mu_S)}{\sigma_S}$$ que tem média 0 e variância 1, representada na figura abaixo, onde são mostrados os limites de aceitação dos valores de **z**. 

```{r }
x <- seq(-4,4,by = 0.01)
dfnorm <- data.frame(x = x, d = dnorm(x))
alpha = 0.05
# teste bilateral
rc_b <- qnorm(alpha/2)
rc_u <- qnorm(1 - alpha/2)
gnorm <- ggplot(data = dfnorm) + geom_line(aes(x=x,y=d))
gnorm <- gnorm + geom_ribbon(data = subset(dfnorm, x>=-4 & x <= rc_b), aes(ymax = d,x=x), ymin=0, fill='red', colour=NA, alpha=0.5) + geom_ribbon(data = subset(dfnorm, x>=rc_u & x < 4), aes(ymax = d, x=x), ymin=0, fill='red', colour=NA, alpha=0.5)  + geom_ribbon(data = subset(dfnorm, x>=rc_b & x <= rc_u+0.011), aes(ymax = d, x = x), ymin=0, fill='blue', colour=NA, alpha=0.3) + theme_light() +  theme(plot.caption = element_text(hjust = 0)) + labs(x="z", y='Densidade de Probabilidade' )
#gnorm <- gnorm + geom_segment(aes(x = -abs(z), y = dnorm(-abs(z)), xend = -abs(z), yend = 0,colour='z'), colour='blue') + geom_segment(aes(x = abs(z), y = dnorm(abs(z)), xend = abs(z), yend = 0,colour='z'), colour='blue')
gnorm <- gnorm + annotate("text",x = -abs(rc_b), y = -0.025, label = "-|z.alpha|", size = 3.5) 
gnorm <- gnorm + annotate("text",x = abs(rc_u), y = -0.025, label = "|z.alpha|", size = 3.5)
gnorm <- gnorm + annotate("text", x = rc_b - 0.1, y = dnorm(-rc_b) + 0.025, label = as.character( expression( paste( alpha,"/2"))), parse = TRUE, size = 4)
gnorm <- gnorm + annotate ("text", x = rc_u + 0.1, y = dnorm(rc_u) + 0.025, label = as.character( expression( paste( alpha,"/2"))), parse = TRUE, size = 4)
gnorm <- gnorm + annotate("text", x = 0, y = 0.2, label = as.character(expression(paste("Região de Aceitação"))), parse = TRUE, size = 4)
gnorm + geom_segment(aes(x = -2.5,y = 0.01, xend = -3, yend = 0.05), colour = 'black',size = 0.1) + annotate("text", x = -3, y = 0.06, label = as.character(expression(paste("Região Crítica"))), parse = TRUE, size = 4) + geom_segment(aes(x = 2.5,y = 0.01, xend = 3, yend = 0.05), colour = 'black',size = 0.1) + annotate("text", x = -3, y = 0.06, label = as.character(expression(paste("Região Crítica"))), parse = TRUE, size = 4) + annotate("text", x = 3, y = 0.06, label = as.character(expression(paste("Região Crítica"))), parse = TRUE, size = 4) + scale_x_continuous(name="X", limits=c(-4, 4), breaks=seq(-4, 4,by=0.5)) +
  ggtitle("Curva normal da variável reduzida 'z'", subtitle = "Regiões de Aceitação e Rejeição, teste bilateral")
```


Quando utilizamos uma amostra de tamanho reduzido, p.explo, $n = 30$, utilizamos a média amostral como estimador da média populacional, e o *erro padrão da média* como estimador do desvio padrão populacional, ou seja, $\sigma_S = \sigma_{\bar{x}} = \sigma/\sqrt{N}$, onde $\sigma$ é o desvio padrão da população e $N$ o tamanho da amostra. O *escore* **z** será dado então por: $$z = \frac{\bar{x} - \mu}{\sigma/\sqrt{N}}$$ onde $\bar{x}$ é a média amostral.

Os passos para realizar o Teste de Hipótese, considerando um nível de significância $\alpha = 0.05$,  são:

1. Calcular a estatística de teste -- no caso, estatística $z$, porque **assumimos que nossos dados seguem uma distribuição normal** e conhecemos a média e o desvio padrão da população;


2. Calcular o valor crítico para o nível de significância definido, isto é, quais os limites da variável reduzida que definem a Região de Aceitação da Hipótese Nula ($\textrm{H}_0$);
$$\textrm{z.alpha} = \texttt{qnorm}(1 - \alpha/2)$$
3. Verificar se o valor da estatística de teste está na *Região de Aceitação* ou na *Região Crítica ou de Rejeição*  da hipótese nula. Uma definição importante é se o teste é unilateral ou bilateral. Para esse exemplo, vamos considerar um teste **bilateral**, ou seja, queremos saber se o peso médio dos animais mudou.


### Teste de Hipótese


#### Amostra com menor média


```{r}
xbar <- min(mediasamostrasSS30)
n <- 30
alpha = 0.05
z <- (xbar - media)/(desvio/sqrt(n))
z.alpha <- qnorm(1 - alpha/2)
```


Os resultados dos cálculos são:

Grandeza      |       Valor
--------------|-----------------
Média Popul.  |   `r media`
Desvio Padrão |   `r desvio`
Tam.Amostra   |    `r n`
Média Amostra |    `r xbar`
Estat. **z**  |   `r z`
Limites Críticos |  `r c(-z.alpha,z.alpha)`


Então, o resultado do teste é:

```{r}
if(z > abs(z.alpha)) cat("Estatística de teste z está fora da região de aceitação, portanto rejeitamos a hipótese nula.") else cat("Estatística de teste z está dentro da região de aceitação, portanto aceitamos a hipótese nula.")
```


#### Amostra com maior média


```{r}
xbar <- max(mediasamostrasSS30)
n <- 30
alpha = 0.05
z <- (xbar - media)/(desvio/sqrt(n))
z.alpha <- qnorm(1 - alpha/2)
```


Os resultados dos cálculos são:

Grandeza      |       Valor
--------------|-----------------
Média Popul.  |   `r media`
Desvio Padrão |   `r desvio`
Tam.Amostra   |    `r n`
Média Amostra |    `r xbar`
Estat. **z**  |   `r z`
Limites Críticos |  `r c(-z.alpha,z.alpha)`


Então, o resultado do teste é:

```{r}
if(z > abs(z.alpha)) cat("Estatística de teste z está fora da região de aceitação, portanto rejeitamos a hipótese nula.") else cat("Estatística de teste z está dentro da região de aceitação, portanto aceitamos a hipótese nula.")
```


Observe que nós selecionamos as duas amostras acima da mesma população, mas mesmo assim, pelo Teste de Hipótese, uma delas, a de peso médio maior, tem um peso médio que não podemos afirmar que seja da mesma população original; ele pode ser considerado como oriundo de outra distribuição que não a original. 

> Quando realizamos um Teste de Hipótese estamos querendo verificar se a amostra analisada vem ou não da população original para a qual conhecemos os parâmetros. A média amostral será o valor utilizado na verificação.



<!-- 

É lógico que os animais do nosso exemplo não têm peso cuja média seja zero! E nem desvio padrão igual a 1. Então, porque a curva mostrada tem média = 0 e desvio padrão = 1?

É que estamos mostrando a distribuição normal padronizada, cuja área é igual a 1. Ou seja, a soma de todas as probabilidades deve ser 1.

Para transformar os valores de peso dos animais com esta restrição, usamos uma 
Essa técnica é chamada de normalização (ou padronização); consiste em transformar o valor original da variável, centrando-o em torno de uma das medidas de posição central (a média é uma delas) e mudando sua escala para uma das medidas de dispersão da distribuição (o desvio padrão é uma delas). 

Assim, os novos valores serão calculados como:
$$z = \frac{x_i - \bar{x}}{\sqrt(n)\times \sigma}$$

-->




## Populações ou Efeitos Modificadores

Continuando nosso exemplo da população de animais que estamos estudando, suponha agora que houve algum evento, ou fator, que tenha alterado o suprimento de alimento para os animais. Nessa situação, depois de algum tempo, pode ter havido uma *diminuição* do peso (massa corporal) destes animais.

```{r}
# poderia adicionar um delta variável a cada valor de y para gerar a segunda população
#y2 <- df$`Peso(kg)` + runif(length(df$x),min = -.7, max = -.2)
# mas vou definir a segunda população com media 2.9 e desvio 0.8
media2 = 3.0
desvio2 = 0.8
tam = 8000
# gerando a segunda população da mesma maneira da original, i.e., especificando
# média e desvio padrão - vou usar este método
set.seed(1234)
y2 <- rnorm(tam, mean = media2, sd = desvio2)
df$Pop <- "Original"
df2 <- bind_rows(tibble(x = df$x, `Peso(kg)` = y2, Pop = "Nova"), df)
```


Se fizéssemos um senso novamente, pesando todos os animas daquela população, poderíamos encontrar uma *nova distribuição de pesos*, gerando uma segunda curva, como mostrado na figura abaixo. Essa *nova população* tem média `r media2` e desvio padrão `r desvio2`.


```{r }
g2 <- ggplot(data = df2, aes(x = `Peso(kg)`, after_stat(density))) + 
  geom_density(aes(color = Pop), outline.type = "full") + 
  #geom_histogram(aes(fill = Pop), alpha = 0.3 ) +
  labs(x = "Peso(kg)", y = "Densid.Prob.", color = "População") +
  theme_light() 
ggplotly(g2  + ggtitle(paste("Distribuição dos pesos das populações (n=",tam,")")))
```

Como o desvio padrão desta nova distribuição é um pouco maior que da original, a curva de densidade de probabilidade é mais achatada (larga) e por isso, tem uma altura (máximo da densidade) menor.


### Novas amostras

Se tomamos **uma** amostra da nossa população, sem saber que houve o evento modificador, podemos ter a seguinte situação, ilustrada na figura abaixo.

```{r}
set.seed(12345)
n = 30
amostraorig <- slice_sample(filter(df2, Pop == "Original"), n = n, replace = TRUE)
amostranova <- slice_sample(filter(df2, Pop == "Nova"), n = n, replace = TRUE)
amostraorig$P0 <- 0
amostranova$P0 <- 0.02
pesomedioamostraorig = mean(amostraorig$`Peso(kg)`)
pesomedioamostranova = mean(amostranova$`Peso(kg)`)
g3 <- g2 + geom_point(aes(x = `Peso(kg)`, y = P0), data = amostraorig, color = "blue") +
  geom_segment(aes(x = pesomedioamostraorig, y = 0, xend=pesomedioamostraorig, yend = 0.05), color = "blue") +
  annotate("text", x = 1.09*pesomedioamostraorig, y = 0.07, label = paste("Méd.Am.Orig. ",  round(pesomedioamostraorig,2)), size = 3) +
    geom_point(aes(x = `Peso(kg)`, y = P0), data = amostranova, color = "red") +
    geom_segment(aes(x = pesomedioamostranova, y = 0.02, xend=pesomedioamostranova, yend = 0.05), color = "red") +
  annotate("text", x = .85*pesomedioamostranova, y = 0.085, label = paste("Méd.Am.Nova",  round(pesomedioamostranova,2)), size = 3) +
  ggtitle(paste("Amostras de tamanho = ",n, "\nHistograma e curvas originais"))
ggplotly(g3)
```

Os pontos azuis são elementos tomados da população original enquanto os pontos vermelhos são da nova população. Qualquer uma destas amostras é possível, ou seja, sem saber o que ocorreu, poderíamos ter qualquer uma delas.



```{r }
geragrafs2 <- function(g2, amostraorig, amostranova) {
   amostraorig$P0 <- 0
   amostranova$P0 <- 0.02
   pesomedioamostraorig = mean(amostraorig$`Peso(kg)`)
   pesomedioamostranova = mean(amostranova$`Peso(kg)`)
   g3 <- g2 + geom_point(aes(x = `Peso(kg)`, y = P0), data = amostraorig, color = "blue") +
              geom_segment(aes(x = pesomedioamostraorig, y = 0, xend=pesomedioamostraorig, 
                               yend = 0.05), color = "blue") +
   annotate("text", x = 1.09*pesomedioamostraorig, y = 0.07, label = paste("Méd.Am.Orig. ",
                                                  round(pesomedioamostraorig,2)), size = 3) +
    geom_point(aes(x = `Peso(kg)`, y = P0), data = amostranova, color = "red") +
    geom_segment(aes(x = pesomedioamostranova, y = 0.02, xend=pesomedioamostranova, 
                     yend = 0.05), color = "red") +
    annotate("text", x = .85*pesomedioamostranova, y = 0.085, 
             label = paste("Méd.Am.Nova",  round(pesomedioamostranova,2)), size = 3)
    g3
}

```

```{r}
SSize <- 30
Qtde <- 10
```


Agora vamos gerar `r Qtde` amostras das duas distribuições, para visualizarmos como se comportam as médias.
As amostras tem n = `r SSize`; veja como os valores dos pesos nas amostras (pontos em azul e vermelho) ocorrem em cada uma.

```{r fig.height=20}
amostrasorigN30 <- geraamostras(filter(df2, Pop == "Original"), Qtde, SSize)
amostrasnovaN30 <- geraamostras(filter(df2, Pop == "Nova"), Qtde, SSize)
ams <- rbind(amostrasorigN30,amostrasnovaN30)
graficos2N30 <- list()
seqI <- seq(1,length(ams), by = 2)
seqJ <- 1:round(length(ams)/2)
seqs <- list(seqI=seqI, seqJ=seqJ)
for (I in 1:length(seqs$seqI)) {
  graficos2N30[[seqs$seqJ[I]]] <- geragrafs2(g2, ams[[seqs$seqI[I]]], ams[[seqs$seqI[I]+1]])
}
ggarrange(plotlist = graficos2N30, nrow = 5, ncol = 2)  %>%
  annotate_figure(top = text_grob(paste0("Experimento com ", Qtde, " amostras de tamanho = ", SSize,
                                         "\nHistograma e curva densid. originais"), face = "bold", size = 16))
```

Veja como as médias das amostras de ambas distribuições vagueiam ao longo da distribuição de pesos, ora para um lado ora para o outro lado. Se aumentássemos o número de amostras essa variação ficaria ainda mais evidente.

Uma das possibilidades neste tipo de experimento (grande quantidade de amostras) é a mostrada na figura abaixo, onde temos duas amostras com médias muito próximas, mas vindo de populações diferentes. 

```{r}
mediasamostrasorigSS30 <- sapply(amostrasorigN30, function(x) {
  mediaPeso <- mean(x$`Peso(kg)`, na.rm = TRUE)
  mediaPeso
}
)

mediasamostrasnovaSS30 <- sapply(amostrasnovaN30, function(x) {
  mediaPeso <- mean(x$`Peso(kg)`, na.rm = TRUE)
  mediaPeso
}
)


menormedia2 <- which(mediasamostrasorigSS30 == min(mediasamostrasorigSS30))
maiormedia2 <- which(mediasamostrasnovaSS30 == max(mediasamostrasnovaSS30))
ggarrange(graficos2N30[[menormedia2]],graficos2N30[[maiormedia2]])# %>%
#  annotate_figure(top = text_grob(paste0("Amostras de tamanho n = 30",
#                                         "\nHistograma e curva densid. originais"), face = "bold", size = 16))
```

Uma coincidência ocorreu na figura anterior: tanto o gráfico com a amostra da nova população com a maior média como o gráfico com a amostra da população original com a menor média são os mesmos; poderiam ser diferentes, ou seja, a amostra da nova população com a maior média poderia estar em um gráfico e a amostra da população original com a menor média poderia estar em outro.


### Teste de Hipótese

Agora, vamos realizar o Teste de Hipótese da seguinte forma:

1. Selecionando a amostra da população, primeiro da original com menor média, e depois da nova com maior média; 
2. Calcular dois valores de estatística **z**:
    * Um para a população original (**z.orig**)
    * Um para a nova população (**z.nova**)
3. Realizar o teste.


#### Amostra da população original com menor média


```{r}
xbar <- min(mediasamostrasorigSS30)
n <- 30
alpha = 0.05
z.orig <- (xbar - media)/(desvio/sqrt(n))
z.nova <- (xbar - media2)/(desvio2/sqrt(n))
z.alpha <- qnorm(1 - alpha/2)
```


Os resultados dos cálculos são:

Grandeza      |     População     |    Valor
--------------|-------------------|----------------
Média Popul.  |     Original      | `r media`
Média Popul.  |     Nova          | `r media2`
Desvio Padrão |  Original         | `r desvio`
Desvio Padrão |  Nova             | `r desvio2`
Tam.Amostra   |    Ambas          |  `r n`
Média Amostra |    Original       |  `r xbar`
Estat. **z** (Amostra/População)  |    Original/Original  |  `r z.orig`
Estat. **z** (Amostra/População) |    Original/Nova      |  `r z.nova`
Limites Críticos | Ambas          |  `r c(-z.alpha,z.alpha)`


**Resultado do Teste em relação à população original**

```{r}
if(abs(z.orig) > abs(z.alpha)) cat("Estatística de teste z está fora da região de aceitação, portanto rejeitamos a hipótese nula.") else cat("Estatística de teste z está dentro da região de aceitação, portanto aceitamos a hipótese nula.")
```

**Resultado do Teste em relação à população nova**

```{r}
if(abs(z.nova) > abs(z.alpha)) cat("Estatística de teste z está fora da região de aceitação, portanto rejeitamos a hipótese nula.") else cat("Estatística de teste z está dentro da região de aceitação, portanto aceitamos a hipótese nula.")
```


A amostra tomada da população original **passou** no teste em relação à sua própria população, mas foi **rejeitada** no teste em relação à nova população.


#### Amostra da nova população com maior média


```{r}
xbar2 <- max(mediasamostrasnovaSS30)
n <- 30
alpha = 0.05
z.nova2 <- (xbar2 - media2)/(desvio2/sqrt(n))
z.orig2 <- (xbar2 - media)/(desvio/sqrt(n))
z.alpha <- qnorm(1 - alpha/2)
```


Os resultados dos cálculos são:

Grandeza      |     População     |    Valor
--------------|-------------------|----------------
Média Popul.  |     Original      | `r media`
Média Popul.  |     Nova          | `r media2`
Desvio Padrão |  Original         | `r desvio`
Desvio Padrão |  Nova             | `r desvio2`
Tam.Amostra   |    Ambas          |  `r n`
Média Amostra |    Nova           |  `r xbar2`
Estat. **z** (Amostra/População)  |    Nova/Original   | `r z.orig2`
Estat. **z** (Amostra/População)  |    Nova/Nova      |   `r z.nova2`
Limites Críticos | Ambas          |  `r c(-z.alpha,z.alpha)`


**Resultado do Teste em relação à população original**

```{r}
if(abs(z.orig2) > abs(z.alpha)) cat("Estatística de teste z está fora da região de aceitação, portanto rejeitamos a hipótese nula.") else cat("Estatística de teste z está dentro da região de aceitação, portanto aceitamos a hipótese nula.")
```

**Resultado do Teste em relação à população nova**

```{r}
if(abs(z.nova2) > abs(z.alpha)) cat("Estatística de teste z está fora da região de aceitação, portanto rejeitamos a hipótese nula.") else cat("Estatística de teste z está dentro da região de aceitação, portanto aceitamos a hipótese nula.")
```


Observe que a amostra tomada da nova população **passou** no teste em relação à população original, assim como **passou** no teste em relação à sua própria população (a nova). Neste caso, nosso biólogo não poderia afirmar que houve algum evento que de fato modificou a média de peso da população, porque na amostra tomada de forma aleatória, a média estava dentro dos limites de aceitação também da população original.

### Grande número de amostras de ambas as populações

Vamos realizar um experimento, selecionando um grande número de amostras de ambas as populações e tabulando o resultado do teste de hipótese em relação a ambas.

```{r}
SSize <- 30
Qtde <- 100
cemamostrasorigN30 <- geraamostras(filter(df2, Pop == "Original"), Qtde, SSize)
cemamostrasnovaN30 <- geraamostras(filter(df2, Pop == "Nova"), Qtde, SSize)
cemams <- rbind(cemamostrasorigN30,cemamostrasnovaN30)
```


